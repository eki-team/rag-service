# üîÑ Migraci√≥n a OpenAI Embeddings

## ‚úÖ Cambios Realizados

### 1. **Nuevo Servicio de Embeddings**
- **Archivo:** `app/services/embeddings/openai_embeddings.py`
- **Modelo:** `text-embedding-3-small` (OpenAI)
- **Dimensiones:** 1536 (antes: 384)
- **Costo:** $0.02 / 1M tokens

### 2. **Configuraci√≥n Actualizada**
`.env`:
```properties
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536
EMBEDDING_BATCH_SIZE=100
```

### 3. **Ventajas de OpenAI Embeddings**
‚úÖ Mejor calidad de b√∫squeda sem√°ntica
‚úÖ Soporte multiling√ºe superior
‚úÖ M√°s dimensiones (1536 vs 384)
‚úÖ No requiere descargar modelos locales
‚úÖ Sin dependencia de PyTorch/transformers
‚ùå Costo por uso (pero muy econ√≥mico: $0.02/1M tokens)

---

## ‚ö†Ô∏è IMPORTANTE: Actualizar √çndice Vectorial en MongoDB

Como cambiaste de **384 dimensiones** a **1536 dimensiones**, **DEBES recrear el √≠ndice vectorial** en MongoDB Atlas.

### Opci√≥n 1: Recrear √çndice en MongoDB Atlas UI

1. Ve a MongoDB Atlas ‚Üí Database ‚Üí Collections
2. Selecciona `mydb.pub_chunks`
3. Ve a "Search Indexes"
4. **ELIMINA** el √≠ndice `vector_index` actual (384 dims)
5. Crea nuevo √≠ndice con esta configuraci√≥n:

```json
{
  "fields": [
    {
      "type": "vector",
      "path": "embedding",
      "numDimensions": 1536,
      "similarity": "cosine"
    }
  ]
}
```

### Opci√≥n 2: Crear √çndice con MongoDB Shell

```javascript
use mydb;

// Eliminar √≠ndice viejo
db.pub_chunks.dropIndex("vector_index");

// Crear √≠ndice nuevo (1536 dims)
db.pub_chunks.createSearchIndex(
  "vector_index",
  "vectorSearch",
  {
    fields: [
      {
        type: "vector",
        path: "embedding",
        numDimensions: 1536,
        similarity: "cosine"
      }
    ]
  }
);
```

---

## üîÑ Re-indexar Documentos

**IMPORTANTE:** Todos los embeddings existentes en MongoDB son de 384 dimensiones. Necesitas regenerarlos con OpenAI.

### Script de Re-indexaci√≥n:

```python
# re_index_with_openai.py
from pymongo import MongoClient
from app.services.embeddings import get_embeddings_service
from app.core.settings import settings
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def re_index_documents():
    """Re-indexa todos los documentos con OpenAI embeddings"""
    
    # Conectar a MongoDB
    client = MongoClient(settings.MONGODB_URI)
    db = client[settings.MONGODB_DB]
    collection = db[settings.MONGODB_COLLECTION]
    
    # Inicializar servicio de embeddings
    embeddings_service = get_embeddings_service()
    
    # Obtener todos los documentos
    total = collection.count_documents({})
    logger.info(f"üìä Total documents to re-index: {total}")
    
    # Procesar en batches
    batch_size = 100
    processed = 0
    
    for skip in range(0, total, batch_size):
        # Obtener batch
        docs = list(collection.find({}, {"_id": 1, "text": 1}).skip(skip).limit(batch_size))
        
        if not docs:
            break
        
        # Extraer textos
        texts = [doc["text"] for doc in docs]
        doc_ids = [doc["_id"] for doc in docs]
        
        # Generar embeddings con OpenAI
        logger.info(f"üîÑ Generating embeddings for batch {skip}-{skip+len(docs)}...")
        embeddings = embeddings_service.encode_documents(texts, batch_size=100)
        
        # Actualizar en MongoDB
        for doc_id, embedding in zip(doc_ids, embeddings):
            collection.update_one(
                {"_id": doc_id},
                {"$set": {"embedding": embedding}}
            )
        
        processed += len(docs)
        logger.info(f"‚úÖ Processed {processed}/{total} documents ({processed/total*100:.1f}%)")
    
    logger.info(f"üéâ Re-indexing complete! {processed} documents updated")

if __name__ == "__main__":
    re_index_documents()
```

**Ejecutar:**
```bash
python re_index_with_openai.py
```

---

## üß™ Testing

### 1. Probar servicio de embeddings:

```bash
curl -X POST "http://localhost:8000/diag/emb" \
  -H "Content-Type: application/json" \
  -d '{"text": "microgravity effects on immune system"}'
```

**Esperas ver:**
```json
{
  "text": "microgravity effects on immune system",
  "embedding_length": 1536,
  "embedding_sample": [0.123, -0.456, ...],
  "model": "text-embedding-3-small"
}
```

### 2. Probar retrieval (sin LLM):

```bash
curl -X POST "http://localhost:8000/diag/retrieval" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are the effects of microgravity?",
    "top_k": 5
  }'
```

### 3. Probar RAG chatbot:

```bash
curl -X POST "http://localhost:8000/api/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "How does spaceflight affect the immune system?",
    "top_k": 8
  }'
```

---

## üí∞ Costos de OpenAI Embeddings

### text-embedding-3-small
- **Precio:** $0.02 / 1M tokens
- **Ejemplo:** 1000 documentos de 500 palabras cada uno = ~375K tokens = **$0.0075** (menos de 1 centavo)

### Comparaci√≥n:
- **Sentence-transformers:** Gratis, pero local (requiere CPU/RAM)
- **OpenAI:** Muy barato, mejor calidad, sin overhead local

---

## üìä Comparaci√≥n: Sentence-Transformers vs OpenAI

| Aspecto | Sentence-Transformers | OpenAI Embeddings |
|---------|----------------------|-------------------|
| **Modelo** | all-MiniLM-L6-v2 | text-embedding-3-small |
| **Dimensiones** | 384 | 1536 |
| **Calidad** | Buena | Excelente |
| **Velocidad** | R√°pido (local) | Depende de API |
| **Costo** | Gratis | $0.02/1M tokens |
| **Dependencias** | PyTorch, transformers | openai (ligero) |
| **Tama√±o modelo** | ~90MB | N/A (API) |
| **Uso RAM** | ~500MB | M√≠nimo |
| **Multiling√ºe** | Bueno | Excelente |

---

## üöÄ Pr√≥ximos Pasos

1. ‚úÖ **Servicio creado** - OpenAI embeddings listo
2. ‚ö†Ô∏è **Actualizar √≠ndice MongoDB** - Cambiar de 384 a 1536 dims
3. ‚ö†Ô∏è **Re-indexar documentos** - Regenerar embeddings con OpenAI
4. ‚úÖ **Testing** - Probar endpoints `/diag/emb`, `/diag/retrieval`, `/api/chat`

---

## üìù Notas

- Los embeddings de OpenAI son **mejores** para b√∫squeda sem√°ntica
- El modelo es **multiling√ºe** (soporta espa√±ol, ingl√©s, etc.)
- **Costo muy bajo** para proyectos peque√±os/medianos
- Si tienes **muchos documentos** (millones), considera sentence-transformers para ahorrar costos
- Para **producci√≥n**, OpenAI embeddings es la mejor opci√≥n por calidad/costo

---

¬øNecesitas ayuda con la re-indexaci√≥n? ¬°Av√≠same! üöÄ
